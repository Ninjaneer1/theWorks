{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Data: Checkpoint 5\n",
    "\n",
    "In the following task, you'll continue working with the Credit Card Fraud Detection dataset from Kaggle. Before moving on to the tasks, you should load the dataset using Dask.\n",
    "\n",
    "Please submit your solutions to the following tasks as a link to your jupyter notebook on Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dask_ml --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import joblib\n",
    "from dask.distributed import Client, progress\n",
    "from dask_ml.model_selection import train_test_split\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:64121</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>8.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:64121' processes=4 threads=8, memory=8.00 GB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(n_workers=4, threads_per_worker=2, memory_limit='2GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/creditcard.csv'\n",
    "df = dd.read_csv(path, dtype={'Time':'float'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. In this task, you'll train several machine learning models from scikit-learn using Dask as the backend of joblib. This time, you need to use all the variables except `Class` as your feature set. `Class` variable will be your target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=3\n",
       "    int64\n",
       "      ...\n",
       "      ...\n",
       "      ...\n",
       "Name: Class, dtype: int64\n",
       "Dask Name: split, 3 tasks"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.drop('Class', axis=1)\n",
    "y = df.Class\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=1234)\n",
    "\n",
    "# dataset is small enough to make available to the memory\n",
    "X_train.persist()\n",
    "X_test.persist()\n",
    "y_train.persist()\n",
    "y_test.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg training Score: is 0.8599285843693881\n",
      "LogReg testing Score is 0.8190234345359043\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    lr.fit(X_train.compute(), y_train.compute())\n",
    "    \n",
    "preds_train = lr.predict(X_train.values.compute())\n",
    "preds_test = lr.predict(X_test.values.compute())\n",
    "\n",
    "print('LogReg training Score: is {}'.format(roc_auc_score(preds_train, y_train.values.compute())))\n",
    "print('LogReg testing Score is {}'.format(roc_auc_score(preds_test, y_test.values.compute())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradBoostTree training Score: is 0.9550773417579038\n",
      "GradBoostTree testing Score is 0.8648340797046601\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    gbc.fit(X_train.compute(), y_train.compute())\n",
    "    \n",
    "preds_train = gbc.predict(X_train.values.compute())\n",
    "preds_test = gbc.predict(X_test.values.compute())\n",
    "\n",
    "print('GradBoostTree training Score: is {}'.format(roc_auc_score(preds_train, y_train.values.compute())))\n",
    "print('GradBoostTree testing Score is {}'.format(roc_auc_score(preds_test, y_test.values.compute())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RanForest training score is: 0.9999977988598094\n",
      "RanForest testing score is: 0.9680528489814954\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    rfc.fit(X_train.compute(), y_train.compute())\n",
    "    \n",
    "preds_train = rfc.predict(X_train.values.compute())\n",
    "preds_test = rfc.predict(X_test.values.compute())\n",
    "\n",
    "print(\"RanForest training score is: {}\".format(roc_auc_score(preds_train, y_train.values.compute())))\n",
    "print(\"RanForest testing score is: {}\".format(roc_auc_score(preds_test, y_test.values.compute())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compare the results of your models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest model out-performed the other models in both the training and test scores. No tuning was done to any of the models, and this could change the results. Tuning can be performed with the Grid Search Cross Validation method. The best hyperparameters for each algorithm can then be applied to the algorithms to get their best performance before camparing and making a selection with which to move forward.                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
